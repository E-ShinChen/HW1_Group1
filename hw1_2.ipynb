{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
    "from keras import layers, optimizers, models\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import Image, SVG\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['age','workclass','fnlwgt','education','education_num','marital_status','occupation',\n",
    "            'relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country',\n",
    "            'high_income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pandas.read_csv(\"adult.data\", encoding=\"UTF-8\", names=col_name, header=None)\n",
    "test_data = pandas.read_csv(\"adult.test\", encoding=\"UTF-8\", names=col_name,header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(train_data['education_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt      education  education_num  \\\n",
       "0       25        Private  226802           11th              7   \n",
       "1       38        Private   89814        HS-grad              9   \n",
       "2       28      Local-gov  336951     Assoc-acdm             12   \n",
       "3       44        Private  160323   Some-college             10   \n",
       "4       18              ?  103497   Some-college             10   \n",
       "...    ...            ...     ...            ...            ...   \n",
       "16276   39        Private  215419      Bachelors             13   \n",
       "16277   64              ?  321403        HS-grad              9   \n",
       "16278   38        Private  374983      Bachelors             13   \n",
       "16279   44        Private   83891      Bachelors             13   \n",
       "16280   35   Self-emp-inc  182148      Bachelors             13   \n",
       "\n",
       "            marital_status          occupation     relationship  \\\n",
       "0            Never-married   Machine-op-inspct        Own-child   \n",
       "1       Married-civ-spouse     Farming-fishing          Husband   \n",
       "2       Married-civ-spouse     Protective-serv          Husband   \n",
       "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "4            Never-married                   ?        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital_gain  capital_loss  \\\n",
       "0                    Black     Male             0             0   \n",
       "1                    White     Male             0             0   \n",
       "2                    White     Male             0             0   \n",
       "3                    Black     Male          7688             0   \n",
       "4                    White   Female             0             0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female             0             0   \n",
       "16277                Black     Male             0             0   \n",
       "16278                White     Male             0             0   \n",
       "16279   Asian-Pac-Islander     Male          5455             0   \n",
       "16280                White     Male             0             0   \n",
       "\n",
       "       hours_per_week  native_country high_income  \n",
       "0                  40   United-States      <=50K.  \n",
       "1                  50   United-States      <=50K.  \n",
       "2                  40   United-States       >50K.  \n",
       "3                  40   United-States       >50K.  \n",
       "4                  30   United-States      <=50K.  \n",
       "...               ...             ...         ...  \n",
       "16276              36   United-States      <=50K.  \n",
       "16277              40   United-States      <=50K.  \n",
       "16278              50   United-States      <=50K.  \n",
       "16279              40   United-States      <=50K.  \n",
       "16280              60   United-States       >50K.  \n",
       "\n",
       "[16281 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['high_income'] = test_data['high_income'].str.replace('.', '')\n",
    "train_data = train_data.replace(' ?', np.nan)\n",
    "test_data = test_data.replace(' ?', np.nan)\n",
    "train_data = train_data.dropna() \n",
    "test_data = test_data.dropna() \n",
    "train_data = train_data.drop(['fnlwgt','capital_gain','capital_loss','native_country'],axis = 1)\n",
    "test_data = test_data.drop(['fnlwgt','capital_gain','capital_loss','native_country'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['education']\n",
    "y_test = test_data['education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['education'],axis = 1)\n",
    "X_test = test_data.drop(['education'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot\n",
    "X_train = pd.get_dummies(\n",
    "    X_train,columns = ['workclass','marital_status','occupation','relationship','race','sex','high_income'])\n",
    "X_test = pd.get_dummies(\n",
    "    X_test,columns = ['workclass','marital_status','occupation','relationship','race','sex','high_income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>high_income_ &lt;=50K</th>\n",
       "      <th>high_income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  education_num  hours_per_week  workclass_ Federal-gov  \\\n",
       "0       39             13              40                       0   \n",
       "1       50             13              13                       0   \n",
       "2       38              9              40                       0   \n",
       "3       53              7              40                       0   \n",
       "4       28             13              40                       0   \n",
       "...    ...            ...             ...                     ...   \n",
       "32556   27             12              38                       0   \n",
       "32557   40              9              40                       0   \n",
       "32558   58              9              40                       0   \n",
       "32559   22              9              20                       0   \n",
       "32560   52              9              40                       0   \n",
       "\n",
       "       workclass_ Local-gov  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                         0                   0                        0   \n",
       "1                         0                   0                        0   \n",
       "2                         0                   1                        0   \n",
       "3                         0                   1                        0   \n",
       "4                         0                   1                        0   \n",
       "...                     ...                 ...                      ...   \n",
       "32556                     0                   1                        0   \n",
       "32557                     0                   1                        0   \n",
       "32558                     0                   1                        0   \n",
       "32559                     0                   1                        0   \n",
       "32560                     0                   0                        1   \n",
       "\n",
       "       workclass_ Self-emp-not-inc  workclass_ State-gov  \\\n",
       "0                                0                     1   \n",
       "1                                1                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "4                                0                     0   \n",
       "...                            ...                   ...   \n",
       "32556                            0                     0   \n",
       "32557                            0                     0   \n",
       "32558                            0                     0   \n",
       "32559                            0                     0   \n",
       "32560                            0                     0   \n",
       "\n",
       "       workclass_ Without-pay  ...  relationship_ Wife  \\\n",
       "0                           0  ...                   0   \n",
       "1                           0  ...                   0   \n",
       "2                           0  ...                   0   \n",
       "3                           0  ...                   0   \n",
       "4                           0  ...                   1   \n",
       "...                       ...  ...                 ...   \n",
       "32556                       0  ...                   1   \n",
       "32557                       0  ...                   0   \n",
       "32558                       0  ...                   0   \n",
       "32559                       0  ...                   0   \n",
       "32560                       0  ...                   1   \n",
       "\n",
       "       race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                             0                         0            0   \n",
       "1                             0                         0            0   \n",
       "2                             0                         0            0   \n",
       "3                             0                         0            1   \n",
       "4                             0                         0            1   \n",
       "...                         ...                       ...          ...   \n",
       "32556                         0                         0            0   \n",
       "32557                         0                         0            0   \n",
       "32558                         0                         0            0   \n",
       "32559                         0                         0            0   \n",
       "32560                         0                         0            0   \n",
       "\n",
       "       race_ Other  race_ White  sex_ Female  sex_ Male  high_income_ <=50K  \\\n",
       "0                0            1            0          1                   1   \n",
       "1                0            1            0          1                   1   \n",
       "2                0            1            0          1                   1   \n",
       "3                0            0            0          1                   1   \n",
       "4                0            0            1          0                   1   \n",
       "...            ...          ...          ...        ...                 ...   \n",
       "32556            0            1            1          0                   1   \n",
       "32557            0            1            0          1                   0   \n",
       "32558            0            1            1          0                   1   \n",
       "32559            0            1            0          1                   1   \n",
       "32560            0            1            1          0                   0   \n",
       "\n",
       "       high_income_ >50K  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      0  \n",
       "3                      0  \n",
       "4                      0  \n",
       "...                  ...  \n",
       "32556                  0  \n",
       "32557                  1  \n",
       "32558                  0  \n",
       "32559                  0  \n",
       "32560                  1  \n",
       "\n",
       "[30162 rows x 46 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>high_income_ &lt;=50K</th>\n",
       "      <th>high_income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>13</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  education_num  hours_per_week  workclass_ Federal-gov  \\\n",
       "0       25              7              40                       0   \n",
       "1       38              9              50                       0   \n",
       "2       28             12              40                       0   \n",
       "3       44             10              40                       0   \n",
       "5       34              6              30                       0   \n",
       "...    ...            ...             ...                     ...   \n",
       "16275   33             13              40                       0   \n",
       "16276   39             13              36                       0   \n",
       "16278   38             13              50                       0   \n",
       "16279   44             13              40                       0   \n",
       "16280   35             13              60                       0   \n",
       "\n",
       "       workclass_ Local-gov  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                         0                   1                        0   \n",
       "1                         0                   1                        0   \n",
       "2                         1                   0                        0   \n",
       "3                         0                   1                        0   \n",
       "5                         0                   1                        0   \n",
       "...                     ...                 ...                      ...   \n",
       "16275                     0                   1                        0   \n",
       "16276                     0                   1                        0   \n",
       "16278                     0                   1                        0   \n",
       "16279                     0                   1                        0   \n",
       "16280                     0                   0                        1   \n",
       "\n",
       "       workclass_ Self-emp-not-inc  workclass_ State-gov  \\\n",
       "0                                0                     0   \n",
       "1                                0                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "5                                0                     0   \n",
       "...                            ...                   ...   \n",
       "16275                            0                     0   \n",
       "16276                            0                     0   \n",
       "16278                            0                     0   \n",
       "16279                            0                     0   \n",
       "16280                            0                     0   \n",
       "\n",
       "       workclass_ Without-pay  ...  relationship_ Wife  \\\n",
       "0                           0  ...                   0   \n",
       "1                           0  ...                   0   \n",
       "2                           0  ...                   0   \n",
       "3                           0  ...                   0   \n",
       "5                           0  ...                   0   \n",
       "...                       ...  ...                 ...   \n",
       "16275                       0  ...                   0   \n",
       "16276                       0  ...                   0   \n",
       "16278                       0  ...                   0   \n",
       "16279                       0  ...                   0   \n",
       "16280                       0  ...                   0   \n",
       "\n",
       "       race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                             0                         0            1   \n",
       "1                             0                         0            0   \n",
       "2                             0                         0            0   \n",
       "3                             0                         0            1   \n",
       "5                             0                         0            0   \n",
       "...                         ...                       ...          ...   \n",
       "16275                         0                         0            0   \n",
       "16276                         0                         0            0   \n",
       "16278                         0                         0            0   \n",
       "16279                         0                         1            0   \n",
       "16280                         0                         0            0   \n",
       "\n",
       "       race_ Other  race_ White  sex_ Female  sex_ Male  high_income_ <=50K  \\\n",
       "0                0            0            0          1                   1   \n",
       "1                0            1            0          1                   1   \n",
       "2                0            1            0          1                   0   \n",
       "3                0            0            0          1                   0   \n",
       "5                0            1            0          1                   1   \n",
       "...            ...          ...          ...        ...                 ...   \n",
       "16275            0            1            0          1                   1   \n",
       "16276            0            1            1          0                   1   \n",
       "16278            0            1            0          1                   1   \n",
       "16279            0            0            0          1                   1   \n",
       "16280            0            1            0          1                   0   \n",
       "\n",
       "       high_income_ >50K  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      1  \n",
       "5                      0  \n",
       "...                  ...  \n",
       "16275                  0  \n",
       "16276                  0  \n",
       "16278                  0  \n",
       "16279                  0  \n",
       "16280                  1  \n",
       "\n",
       "[15060 rows x 46 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler 最小最大值標準化\n",
    "X_train_scaler = MinMaxScaler().fit(X_train)\n",
    "X_test_scaler = MinMaxScaler().fit(X_test)\n",
    "X_train = X_train_scaler.transform(X_train)\n",
    "X_test = X_test_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對 label做 one hot\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                3008      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 6,944\n",
      "Trainable params: 6,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\mb207\\Anaconda3\\envs\\opencv\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 24129 samples, validate on 6033 samples\n",
      "Epoch 1/1000\n",
      "24129/24129 [==============================] - 4s 156us/step - loss: 2.1378 - acc: 0.2888 - val_loss: 1.9943 - val_acc: 0.3375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.99432, saving model to ./model.h5\n",
      "Epoch 2/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.8564 - acc: 0.3978 - val_loss: 1.7120 - val_acc: 0.4262\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.99432 to 1.71198, saving model to ./model.h5\n",
      "Epoch 3/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.5176 - acc: 0.4713 - val_loss: 1.2418 - val_acc: 0.5495\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.71198 to 1.24183, saving model to ./model.h5\n",
      "Epoch 4/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 0.9882 - acc: 0.6581 - val_loss: 0.7439 - val_acc: 0.7466\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.24183 to 0.74392, saving model to ./model.h5\n",
      "Epoch 5/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 0.6425 - acc: 0.7699 - val_loss: 0.4879 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74392 to 0.48785, saving model to ./model.h5\n",
      "Epoch 6/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 0.4705 - acc: 0.8310 - val_loss: 0.3553 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.48785 to 0.35529, saving model to ./model.h5\n",
      "Epoch 7/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 0.3789 - acc: 0.8712 - val_loss: 0.2821 - val_acc: 0.9098\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.35529 to 0.28209, saving model to ./model.h5\n",
      "Epoch 8/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.3186 - acc: 0.8978 - val_loss: 0.2220 - val_acc: 0.9528\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.28209 to 0.22201, saving model to ./model.h5\n",
      "Epoch 9/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.2737 - acc: 0.9164 - val_loss: 0.1897 - val_acc: 0.9610\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22201 to 0.18971, saving model to ./model.h5\n",
      "Epoch 10/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.2368 - acc: 0.9297 - val_loss: 0.1566 - val_acc: 0.9571\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18971 to 0.15655, saving model to ./model.h5\n",
      "Epoch 11/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.2129 - acc: 0.9333 - val_loss: 0.1317 - val_acc: 0.9702\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15655 to 0.13175, saving model to ./model.h5\n",
      "Epoch 12/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.1806 - acc: 0.9455 - val_loss: 0.1116 - val_acc: 0.9748\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.13175 to 0.11159, saving model to ./model.h5\n",
      "Epoch 13/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 0.1670 - acc: 0.9511 - val_loss: 0.0971 - val_acc: 0.9778\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.11159 to 0.09714, saving model to ./model.h5\n",
      "Epoch 14/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.1493 - acc: 0.9549 - val_loss: 0.0899 - val_acc: 0.9962\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09714 to 0.08991, saving model to ./model.h5\n",
      "Epoch 15/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 0.1376 - acc: 0.9604 - val_loss: 0.0795 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08991 to 0.07950, saving model to ./model.h5\n",
      "Epoch 16/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 0.1288 - acc: 0.9605 - val_loss: 0.0717 - val_acc: 0.9977\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.07950 to 0.07174, saving model to ./model.h5\n",
      "Epoch 17/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.1192 - acc: 0.9659 - val_loss: 0.0740 - val_acc: 0.9818\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.07174\n",
      "Epoch 18/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.1149 - acc: 0.9666 - val_loss: 0.0681 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.07174 to 0.06808, saving model to ./model.h5\n",
      "Epoch 19/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.1094 - acc: 0.9666 - val_loss: 0.0600 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.06808 to 0.06001, saving model to ./model.h5\n",
      "Epoch 20/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 0.0982 - acc: 0.9714 - val_loss: 0.0489 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.06001 to 0.04891, saving model to ./model.h5\n",
      "Epoch 21/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0953 - acc: 0.9733 - val_loss: 0.0469 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04891 to 0.04686, saving model to ./model.h5\n",
      "Epoch 22/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0928 - acc: 0.9739 - val_loss: 0.0465 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04686 to 0.04648, saving model to ./model.h5\n",
      "Epoch 23/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0831 - acc: 0.9757 - val_loss: 0.0380 - val_acc: 0.9967\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.04648 to 0.03802, saving model to ./model.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0818 - acc: 0.9768 - val_loss: 0.0445 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.03802\n",
      "Epoch 25/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0752 - acc: 0.9779 - val_loss: 0.0347 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03802 to 0.03465, saving model to ./model.h5\n",
      "Epoch 26/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0719 - acc: 0.9776 - val_loss: 0.0504 - val_acc: 0.9718\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.03465\n",
      "Epoch 27/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 0.0707 - acc: 0.9781 - val_loss: 0.0377 - val_acc: 0.9919\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.03465\n",
      "Epoch 28/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0668 - acc: 0.9799 - val_loss: 0.0274 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03465 to 0.02744, saving model to ./model.h5\n",
      "Epoch 29/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0665 - acc: 0.9793 - val_loss: 0.0344 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.02744\n",
      "Epoch 30/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0620 - acc: 0.9814 - val_loss: 0.0278 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.02744\n",
      "Epoch 31/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0647 - acc: 0.9789 - val_loss: 0.0277 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.02744\n",
      "Epoch 32/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0588 - acc: 0.9821 - val_loss: 0.0338 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.02744\n",
      "Epoch 33/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0587 - acc: 0.9815 - val_loss: 0.0293 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.02744\n",
      "Epoch 34/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0582 - acc: 0.9813 - val_loss: 0.0289 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.02744\n",
      "Epoch 35/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0531 - acc: 0.9844 - val_loss: 0.0258 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.02744 to 0.02582, saving model to ./model.h5\n",
      "Epoch 36/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0567 - acc: 0.9811 - val_loss: 0.0158 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.02582 to 0.01579, saving model to ./model.h5\n",
      "Epoch 37/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0528 - acc: 0.9835 - val_loss: 0.0182 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01579\n",
      "Epoch 38/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0504 - acc: 0.9835 - val_loss: 0.0206 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01579\n",
      "Epoch 39/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0505 - acc: 0.9848 - val_loss: 0.0201 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01579\n",
      "Epoch 40/1000\n",
      "24129/24129 [==============================] - 1s 60us/step - loss: 0.0453 - acc: 0.9859 - val_loss: 0.0200 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01579\n",
      "Epoch 41/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0518 - acc: 0.9837 - val_loss: 0.0290 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01579\n",
      "Epoch 42/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0510 - acc: 0.9833 - val_loss: 0.0248 - val_acc: 0.9980\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01579\n",
      "Epoch 43/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0451 - acc: 0.9865 - val_loss: 0.0136 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.01579 to 0.01364, saving model to ./model.h5\n",
      "Epoch 44/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0427 - acc: 0.9881 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.01364\n",
      "Epoch 45/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0431 - acc: 0.9865 - val_loss: 0.0106 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01364 to 0.01055, saving model to ./model.h5\n",
      "Epoch 46/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0387 - acc: 0.9881 - val_loss: 0.0117 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01055\n",
      "Epoch 47/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0382 - acc: 0.9886 - val_loss: 0.0128 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01055\n",
      "Epoch 48/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0394 - acc: 0.9886 - val_loss: 0.0135 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01055\n",
      "Epoch 49/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0435 - acc: 0.9878 - val_loss: 0.0188 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01055\n",
      "Epoch 50/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0358 - acc: 0.9895 - val_loss: 0.0112 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01055\n",
      "Epoch 51/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0352 - acc: 0.9896 - val_loss: 0.0102 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.01055 to 0.01016, saving model to ./model.h5\n",
      "Epoch 52/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0348 - acc: 0.9900 - val_loss: 0.0072 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.01016 to 0.00716, saving model to ./model.h5\n",
      "Epoch 53/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 0.0284 - acc: 0.9925 - val_loss: 0.0075 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00716\n",
      "Epoch 54/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 0.0318 - acc: 0.9918 - val_loss: 0.0073 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00716\n",
      "Epoch 55/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0289 - acc: 0.9920 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00716 to 0.00651, saving model to ./model.h5\n",
      "Epoch 56/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 0.0281 - acc: 0.9928 - val_loss: 0.0063 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00651 to 0.00625, saving model to ./model.h5\n",
      "Epoch 57/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 0.0245 - acc: 0.9940 - val_loss: 0.0058 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00625 to 0.00579, saving model to ./model.h5\n",
      "Epoch 58/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0264 - acc: 0.9929 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00579\n",
      "Epoch 59/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0305 - acc: 0.9910 - val_loss: 0.0056 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00579 to 0.00563, saving model to ./model.h5\n",
      "Epoch 60/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0279 - acc: 0.9923 - val_loss: 0.0045 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00563 to 0.00447, saving model to ./model.h5\n",
      "Epoch 61/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0249 - acc: 0.9928 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00447 to 0.00347, saving model to ./model.h5\n",
      "Epoch 62/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0268 - acc: 0.9927 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00347\n",
      "Epoch 63/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0243 - acc: 0.9937 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00347\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24129/24129 [==============================] - 1s 56us/step - loss: 0.0252 - acc: 0.9928 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00347 to 0.00314, saving model to ./model.h5\n",
      "Epoch 65/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0234 - acc: 0.9936 - val_loss: 0.0078 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00314\n",
      "Epoch 66/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0263 - acc: 0.9930 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00314\n",
      "Epoch 67/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0227 - acc: 0.9942 - val_loss: 0.0131 - val_acc: 0.9973\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00314\n",
      "Epoch 68/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 0.0216 - acc: 0.9942 - val_loss: 0.0069 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00314\n",
      "Epoch 69/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0255 - acc: 0.9927 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00314 to 0.00313, saving model to ./model.h5\n",
      "Epoch 70/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0180 - acc: 0.9959 - val_loss: 0.0078 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00313\n",
      "Epoch 71/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0204 - acc: 0.9945 - val_loss: 0.0056 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00313\n",
      "Epoch 72/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00313\n",
      "Epoch 73/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0218 - acc: 0.9942 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00313 to 0.00263, saving model to ./model.h5\n",
      "Epoch 74/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0166 - acc: 0.9959 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00263\n",
      "Epoch 75/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0182 - acc: 0.9953 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.00263\n",
      "Epoch 76/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 0.0188 - acc: 0.9956 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00263\n",
      "Epoch 77/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.0057 - val_acc: 0.9997\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00263\n",
      "Epoch 78/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.0040 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00263\n",
      "Epoch 79/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0187 - acc: 0.9947 - val_loss: 0.0062 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00263\n",
      "Epoch 80/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0175 - acc: 0.9955 - val_loss: 0.0031 - val_acc: 0.9998\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00263\n",
      "Epoch 81/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0154 - acc: 0.9958 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00263 to 0.00169, saving model to ./model.h5\n",
      "Epoch 82/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0170 - acc: 0.9949 - val_loss: 0.0036 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00169\n",
      "Epoch 83/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0175 - acc: 0.9955 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00169 to 0.00139, saving model to ./model.h5\n",
      "Epoch 84/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0148 - acc: 0.9962 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00139\n",
      "Epoch 85/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00139\n",
      "Epoch 86/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0139 - acc: 0.9960 - val_loss: 0.0034 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00139\n",
      "Epoch 87/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0135 - acc: 0.9963 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00139\n",
      "Epoch 88/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00139\n",
      "Epoch 89/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 0.0140 - acc: 0.9961 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00139\n",
      "Epoch 90/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0186 - acc: 0.9943 - val_loss: 0.0082 - val_acc: 0.9988\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00139\n",
      "Epoch 91/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 0.0139 - acc: 0.9966 - val_loss: 0.0040 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00139\n",
      "Epoch 92/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 0.0138 - acc: 0.9966 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00139\n",
      "Epoch 93/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 0.0153 - acc: 0.9961 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00139\n",
      "Epoch 00093: early stopping\n",
      "[INFO] Best loss: 0.01350170228249114\n",
      "[INFO] Best acc: 0.9966015997372293\n",
      "[INFO] Best val_loss: 0.00139200123869912\n",
      "[INFO] Best val_acc: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 建構 model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, input_shape=(X_train.shape[1],), activation=\"sigmoid\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.05))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(16, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 顯示模型摘要與結構\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, mode='auto', verbose=1)\n",
    "checkpointer = ModelCheckpoint('./model.h5',verbose=1, save_best_only=True)\n",
    "\n",
    "# 開始訓練 model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=1000, batch_size=128, callbacks=[es,checkpointer])\n",
    "\n",
    "print(\"[INFO] Best loss: {}\".format(np.min(history.history['loss'])))\n",
    "print(\"[INFO] Best acc: {}\".format(np.max(history.history['acc'])))\n",
    "print(\"[INFO] Best val_loss: {}\".format(np.min(history.history['val_loss'])))\n",
    "print(\"[INFO] Best val_acc: {}\".format(np.max(history.history['val_acc'])))\n",
    "\n",
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15060/15060 [==============================] - 1s 55us/step\n",
      "Test Acc : 0.9981407702523241\n",
      "Test Loss : 0.008323964422041795\n"
     ]
    }
   ],
   "source": [
    "# 評估指標\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Acc : \" + str(accuracy))\n",
    "print(\"Test Loss : \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.9968421562995259\n",
      "Recall : 0.9981407702523241\n",
      "F1 : 0.9973875396911188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Precision : ' + str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print('Recall : ' + str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print('F1 : ' + str(f1_score(y_true,  y_pred, average='weighted')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36(opencv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
