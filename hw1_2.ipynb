{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, precision_score, recall_score, f1_score\n",
    "from keras import layers, optimizers, models\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import Image, SVG\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = ['age','workclass','fnlwgt','education','education_num','marital_status','occupation',\n",
    "            'relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country',\n",
    "            'high_income']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pandas.read_csv(\"adult.data\", encoding=\"UTF-8\", names=col_name, header=None)\n",
    "test_data = pandas.read_csv(\"adult.test\", encoding=\"UTF-8\", names=col_name,header=None, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age          workclass  fnlwgt    education  education_num  \\\n",
       "0       39          State-gov   77516    Bachelors             13   \n",
       "1       50   Self-emp-not-inc   83311    Bachelors             13   \n",
       "2       38            Private  215646      HS-grad              9   \n",
       "3       53            Private  234721         11th              7   \n",
       "4       28            Private  338409    Bachelors             13   \n",
       "...    ...                ...     ...          ...            ...   \n",
       "32556   27            Private  257302   Assoc-acdm             12   \n",
       "32557   40            Private  154374      HS-grad              9   \n",
       "32558   58            Private  151910      HS-grad              9   \n",
       "32559   22            Private  201490      HS-grad              9   \n",
       "32560   52       Self-emp-inc  287927      HS-grad              9   \n",
       "\n",
       "            marital_status          occupation    relationship    race  \\\n",
       "0            Never-married        Adm-clerical   Not-in-family   White   \n",
       "1       Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                 Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3       Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4       Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "...                    ...                 ...             ...     ...   \n",
       "32556   Married-civ-spouse        Tech-support            Wife   White   \n",
       "32557   Married-civ-spouse   Machine-op-inspct         Husband   White   \n",
       "32558              Widowed        Adm-clerical       Unmarried   White   \n",
       "32559        Never-married        Adm-clerical       Own-child   White   \n",
       "32560   Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "\n",
       "           sex  capital_gain  capital_loss  hours_per_week  native_country  \\\n",
       "0         Male          2174             0              40   United-States   \n",
       "1         Male             0             0              13   United-States   \n",
       "2         Male             0             0              40   United-States   \n",
       "3         Male             0             0              40   United-States   \n",
       "4       Female             0             0              40            Cuba   \n",
       "...        ...           ...           ...             ...             ...   \n",
       "32556   Female             0             0              38   United-States   \n",
       "32557     Male             0             0              40   United-States   \n",
       "32558   Female             0             0              40   United-States   \n",
       "32559     Male             0             0              20   United-States   \n",
       "32560   Female         15024             0              40   United-States   \n",
       "\n",
       "      high_income  \n",
       "0           <=50K  \n",
       "1           <=50K  \n",
       "2           <=50K  \n",
       "3           <=50K  \n",
       "4           <=50K  \n",
       "...           ...  \n",
       "32556       <=50K  \n",
       "32557        >50K  \n",
       "32558       <=50K  \n",
       "32559       <=50K  \n",
       "32560        >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>high_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>?</td>\n",
       "      <td>103497</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16277</th>\n",
       "      <td>64</td>\n",
       "      <td>?</td>\n",
       "      <td>321403</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16281 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age      workclass  fnlwgt      education  education_num  \\\n",
       "0       25        Private  226802           11th              7   \n",
       "1       38        Private   89814        HS-grad              9   \n",
       "2       28      Local-gov  336951     Assoc-acdm             12   \n",
       "3       44        Private  160323   Some-college             10   \n",
       "4       18              ?  103497   Some-college             10   \n",
       "...    ...            ...     ...            ...            ...   \n",
       "16276   39        Private  215419      Bachelors             13   \n",
       "16277   64              ?  321403        HS-grad              9   \n",
       "16278   38        Private  374983      Bachelors             13   \n",
       "16279   44        Private   83891      Bachelors             13   \n",
       "16280   35   Self-emp-inc  182148      Bachelors             13   \n",
       "\n",
       "            marital_status          occupation     relationship  \\\n",
       "0            Never-married   Machine-op-inspct        Own-child   \n",
       "1       Married-civ-spouse     Farming-fishing          Husband   \n",
       "2       Married-civ-spouse     Protective-serv          Husband   \n",
       "3       Married-civ-spouse   Machine-op-inspct          Husband   \n",
       "4            Never-married                   ?        Own-child   \n",
       "...                    ...                 ...              ...   \n",
       "16276             Divorced      Prof-specialty    Not-in-family   \n",
       "16277              Widowed                   ?   Other-relative   \n",
       "16278   Married-civ-spouse      Prof-specialty          Husband   \n",
       "16279             Divorced        Adm-clerical        Own-child   \n",
       "16280   Married-civ-spouse     Exec-managerial          Husband   \n",
       "\n",
       "                      race      sex  capital_gain  capital_loss  \\\n",
       "0                    Black     Male             0             0   \n",
       "1                    White     Male             0             0   \n",
       "2                    White     Male             0             0   \n",
       "3                    Black     Male          7688             0   \n",
       "4                    White   Female             0             0   \n",
       "...                    ...      ...           ...           ...   \n",
       "16276                White   Female             0             0   \n",
       "16277                Black     Male             0             0   \n",
       "16278                White     Male             0             0   \n",
       "16279   Asian-Pac-Islander     Male          5455             0   \n",
       "16280                White     Male             0             0   \n",
       "\n",
       "       hours_per_week  native_country high_income  \n",
       "0                  40   United-States      <=50K.  \n",
       "1                  50   United-States      <=50K.  \n",
       "2                  40   United-States       >50K.  \n",
       "3                  40   United-States       >50K.  \n",
       "4                  30   United-States      <=50K.  \n",
       "...               ...             ...         ...  \n",
       "16276              36   United-States      <=50K.  \n",
       "16277              40   United-States      <=50K.  \n",
       "16278              50   United-States      <=50K.  \n",
       "16279              40   United-States      <=50K.  \n",
       "16280              60   United-States       >50K.  \n",
       "\n",
       "[16281 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['high_income'] = test_data['high_income'].str.replace('.', '')\n",
    "train_data = train_data.replace(' ?', np.nan)\n",
    "test_data = test_data.replace(' ?', np.nan)\n",
    "train_data = train_data.dropna() \n",
    "test_data = test_data.dropna() \n",
    "train_data = train_data.drop(['education_num','fnlwgt','capital_gain','capital_loss','native_country'],axis = 1)\n",
    "test_data = test_data.drop(['education_num','fnlwgt','capital_gain','capital_loss','native_country'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data['education']\n",
    "y_test = test_data['education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(['education'],axis = 1)\n",
    "X_test = test_data.drop(['education'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot\n",
    "X_train = pd.get_dummies(\n",
    "    X_train,columns = ['workclass','marital_status','occupation','relationship','race','sex','high_income'])\n",
    "X_test = pd.get_dummies(\n",
    "    X_test,columns = ['workclass','marital_status','occupation','relationship','race','sex','high_income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>marital_status_ Divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>high_income_ &lt;=50K</th>\n",
       "      <th>high_income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  hours_per_week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0       39              40                       0                     0   \n",
       "1       50              13                       0                     0   \n",
       "2       38              40                       0                     0   \n",
       "3       53              40                       0                     0   \n",
       "4       28              40                       0                     0   \n",
       "...    ...             ...                     ...                   ...   \n",
       "32556   27              38                       0                     0   \n",
       "32557   40              40                       0                     0   \n",
       "32558   58              40                       0                     0   \n",
       "32559   22              20                       0                     0   \n",
       "32560   52              40                       0                     0   \n",
       "\n",
       "       workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                       0                        0   \n",
       "1                       0                        0   \n",
       "2                       1                        0   \n",
       "3                       1                        0   \n",
       "4                       1                        0   \n",
       "...                   ...                      ...   \n",
       "32556                   1                        0   \n",
       "32557                   1                        0   \n",
       "32558                   1                        0   \n",
       "32559                   1                        0   \n",
       "32560                   0                        1   \n",
       "\n",
       "       workclass_ Self-emp-not-inc  workclass_ State-gov  \\\n",
       "0                                0                     1   \n",
       "1                                1                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "4                                0                     0   \n",
       "...                            ...                   ...   \n",
       "32556                            0                     0   \n",
       "32557                            0                     0   \n",
       "32558                            0                     0   \n",
       "32559                            0                     0   \n",
       "32560                            0                     0   \n",
       "\n",
       "       workclass_ Without-pay  marital_status_ Divorced  ...  \\\n",
       "0                           0                         0  ...   \n",
       "1                           0                         0  ...   \n",
       "2                           0                         1  ...   \n",
       "3                           0                         0  ...   \n",
       "4                           0                         0  ...   \n",
       "...                       ...                       ...  ...   \n",
       "32556                       0                         0  ...   \n",
       "32557                       0                         0  ...   \n",
       "32558                       0                         0  ...   \n",
       "32559                       0                         0  ...   \n",
       "32560                       0                         0  ...   \n",
       "\n",
       "       relationship_ Wife  race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       1                         0                         0   \n",
       "...                   ...                       ...                       ...   \n",
       "32556                   1                         0                         0   \n",
       "32557                   0                         0                         0   \n",
       "32558                   0                         0                         0   \n",
       "32559                   0                         0                         0   \n",
       "32560                   1                         0                         0   \n",
       "\n",
       "       race_ Black  race_ Other  race_ White  sex_ Female  sex_ Male  \\\n",
       "0                0            0            1            0          1   \n",
       "1                0            0            1            0          1   \n",
       "2                0            0            1            0          1   \n",
       "3                1            0            0            0          1   \n",
       "4                1            0            0            1          0   \n",
       "...            ...          ...          ...          ...        ...   \n",
       "32556            0            0            1            1          0   \n",
       "32557            0            0            1            0          1   \n",
       "32558            0            0            1            1          0   \n",
       "32559            0            0            1            0          1   \n",
       "32560            0            0            1            1          0   \n",
       "\n",
       "       high_income_ <=50K  high_income_ >50K  \n",
       "0                       1                  0  \n",
       "1                       1                  0  \n",
       "2                       1                  0  \n",
       "3                       1                  0  \n",
       "4                       1                  0  \n",
       "...                   ...                ...  \n",
       "32556                   1                  0  \n",
       "32557                   0                  1  \n",
       "32558                   1                  0  \n",
       "32559                   1                  0  \n",
       "32560                   0                  1  \n",
       "\n",
       "[30162 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>marital_status_ Divorced</th>\n",
       "      <th>...</th>\n",
       "      <th>relationship_ Wife</th>\n",
       "      <th>race_ Amer-Indian-Eskimo</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>sex_ Female</th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>high_income_ &lt;=50K</th>\n",
       "      <th>high_income_ &gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  hours_per_week  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0       25              40                       0                     0   \n",
       "1       38              50                       0                     0   \n",
       "2       28              40                       0                     1   \n",
       "3       44              40                       0                     0   \n",
       "5       34              30                       0                     0   \n",
       "...    ...             ...                     ...                   ...   \n",
       "16275   33              40                       0                     0   \n",
       "16276   39              36                       0                     0   \n",
       "16278   38              50                       0                     0   \n",
       "16279   44              40                       0                     0   \n",
       "16280   35              60                       0                     0   \n",
       "\n",
       "       workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                       1                        0   \n",
       "1                       1                        0   \n",
       "2                       0                        0   \n",
       "3                       1                        0   \n",
       "5                       1                        0   \n",
       "...                   ...                      ...   \n",
       "16275                   1                        0   \n",
       "16276                   1                        0   \n",
       "16278                   1                        0   \n",
       "16279                   1                        0   \n",
       "16280                   0                        1   \n",
       "\n",
       "       workclass_ Self-emp-not-inc  workclass_ State-gov  \\\n",
       "0                                0                     0   \n",
       "1                                0                     0   \n",
       "2                                0                     0   \n",
       "3                                0                     0   \n",
       "5                                0                     0   \n",
       "...                            ...                   ...   \n",
       "16275                            0                     0   \n",
       "16276                            0                     0   \n",
       "16278                            0                     0   \n",
       "16279                            0                     0   \n",
       "16280                            0                     0   \n",
       "\n",
       "       workclass_ Without-pay  marital_status_ Divorced  ...  \\\n",
       "0                           0                         0  ...   \n",
       "1                           0                         0  ...   \n",
       "2                           0                         0  ...   \n",
       "3                           0                         0  ...   \n",
       "5                           0                         0  ...   \n",
       "...                       ...                       ...  ...   \n",
       "16275                       0                         0  ...   \n",
       "16276                       0                         1  ...   \n",
       "16278                       0                         0  ...   \n",
       "16279                       0                         1  ...   \n",
       "16280                       0                         0  ...   \n",
       "\n",
       "       relationship_ Wife  race_ Amer-Indian-Eskimo  race_ Asian-Pac-Islander  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "5                       0                         0                         0   \n",
       "...                   ...                       ...                       ...   \n",
       "16275                   0                         0                         0   \n",
       "16276                   0                         0                         0   \n",
       "16278                   0                         0                         0   \n",
       "16279                   0                         0                         1   \n",
       "16280                   0                         0                         0   \n",
       "\n",
       "       race_ Black  race_ Other  race_ White  sex_ Female  sex_ Male  \\\n",
       "0                1            0            0            0          1   \n",
       "1                0            0            1            0          1   \n",
       "2                0            0            1            0          1   \n",
       "3                1            0            0            0          1   \n",
       "5                0            0            1            0          1   \n",
       "...            ...          ...          ...          ...        ...   \n",
       "16275            0            0            1            0          1   \n",
       "16276            0            0            1            1          0   \n",
       "16278            0            0            1            0          1   \n",
       "16279            0            0            0            0          1   \n",
       "16280            0            0            1            0          1   \n",
       "\n",
       "       high_income_ <=50K  high_income_ >50K  \n",
       "0                       1                  0  \n",
       "1                       1                  0  \n",
       "2                       0                  1  \n",
       "3                       0                  1  \n",
       "5                       1                  0  \n",
       "...                   ...                ...  \n",
       "16275                   1                  0  \n",
       "16276                   1                  0  \n",
       "16278                   1                  0  \n",
       "16279                   1                  0  \n",
       "16280                   0                  1  \n",
       "\n",
       "[15060 rows x 45 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler 最小最大值標準化\n",
    "X_train_scaler = MinMaxScaler().fit(X_train)\n",
    "X_test_scaler = MinMaxScaler().fit(X_test)\n",
    "X_train = X_train_scaler.transform(X_train)\n",
    "X_test = X_test_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對 label做 one hot\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3831: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3008: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                2944      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "=================================================================\n",
      "Total params: 6,880\n",
      "Trainable params: 6,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\anaconda\\envs\\CV2\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 24129 samples, validate on 6033 samples\n",
      "Epoch 1/1000\n",
      "24129/24129 [==============================] - 13s 544us/step - loss: 2.1043 - acc: 0.3116 - val_loss: 1.9344 - val_acc: 0.3584\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.93442, saving model to ./model.h5\n",
      "Epoch 2/1000\n",
      "24129/24129 [==============================] - 1s 60us/step - loss: 1.8356 - acc: 0.3873 - val_loss: 1.8138 - val_acc: 0.3950\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.93442 to 1.81383, saving model to ./model.h5\n",
      "Epoch 3/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.7798 - acc: 0.4039 - val_loss: 1.7887 - val_acc: 0.3958\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.81383 to 1.78866, saving model to ./model.h5\n",
      "Epoch 4/1000\n",
      "24129/24129 [==============================] - 1s 60us/step - loss: 1.7647 - acc: 0.4047 - val_loss: 1.7780 - val_acc: 0.3993\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.78866 to 1.77803, saving model to ./model.h5\n",
      "Epoch 5/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.7574 - acc: 0.4035 - val_loss: 1.7719 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.77803 to 1.77194, saving model to ./model.h5\n",
      "Epoch 6/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.7498 - acc: 0.4039 - val_loss: 1.7657 - val_acc: 0.4020\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.77194 to 1.76575, saving model to ./model.h5\n",
      "Epoch 7/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 1.7452 - acc: 0.4093 - val_loss: 1.7640 - val_acc: 0.4021\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.76575 to 1.76395, saving model to ./model.h5\n",
      "Epoch 8/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.7371 - acc: 0.4141 - val_loss: 1.7638 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.76395 to 1.76384, saving model to ./model.h5\n",
      "Epoch 9/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.7379 - acc: 0.4099 - val_loss: 1.7547 - val_acc: 0.4044\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.76384 to 1.75473, saving model to ./model.h5\n",
      "Epoch 10/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.7318 - acc: 0.4097 - val_loss: 1.7516 - val_acc: 0.4038\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.75473 to 1.75163, saving model to ./model.h5\n",
      "Epoch 11/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.7299 - acc: 0.4110 - val_loss: 1.7506 - val_acc: 0.4116\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.75163 to 1.75059, saving model to ./model.h5\n",
      "Epoch 12/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.7281 - acc: 0.4129 - val_loss: 1.7482 - val_acc: 0.4074\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.75059 to 1.74816, saving model to ./model.h5\n",
      "Epoch 13/1000\n",
      "24129/24129 [==============================] - 2s 63us/step - loss: 1.7248 - acc: 0.4137 - val_loss: 1.7460 - val_acc: 0.4088\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.74816 to 1.74603, saving model to ./model.h5\n",
      "Epoch 14/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.7233 - acc: 0.4128 - val_loss: 1.7444 - val_acc: 0.4088\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.74603 to 1.74439, saving model to ./model.h5\n",
      "Epoch 15/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.7234 - acc: 0.4148 - val_loss: 1.7448 - val_acc: 0.4058\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.7189 - acc: 0.4142 - val_loss: 1.7378 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.74439 to 1.73782, saving model to ./model.h5\n",
      "Epoch 17/1000\n",
      "24129/24129 [==============================] - ETA: 0s - loss: 1.7167 - acc: 0.415 - 1s 53us/step - loss: 1.7168 - acc: 0.4151 - val_loss: 1.7379 - val_acc: 0.4139\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.7165 - acc: 0.4146 - val_loss: 1.7390 - val_acc: 0.4074\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.7145 - acc: 0.4163 - val_loss: 1.7351 - val_acc: 0.4119\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.73782 to 1.73511, saving model to ./model.h5\n",
      "Epoch 20/1000\n",
      "24129/24129 [==============================] - 1s 62us/step - loss: 1.7148 - acc: 0.4168 - val_loss: 1.7302 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.73511 to 1.73019, saving model to ./model.h5\n",
      "Epoch 21/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.7107 - acc: 0.4174 - val_loss: 1.7279 - val_acc: 0.4141\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.73019 to 1.72791, saving model to ./model.h5\n",
      "Epoch 22/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.7085 - acc: 0.4181 - val_loss: 1.7310 - val_acc: 0.4068\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.7059 - acc: 0.4190 - val_loss: 1.7360 - val_acc: 0.4086\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/1000\n",
      "24129/24129 [==============================] - 1s 49us/step - loss: 1.7051 - acc: 0.4195 - val_loss: 1.7252 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.72791 to 1.72525, saving model to ./model.h5\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.7037 - acc: 0.4192 - val_loss: 1.7220 - val_acc: 0.4184\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.72525 to 1.72197, saving model to ./model.h5\n",
      "Epoch 26/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.7001 - acc: 0.4197 - val_loss: 1.7203 - val_acc: 0.4147\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.72197 to 1.72027, saving model to ./model.h5\n",
      "Epoch 27/1000\n",
      "24129/24129 [==============================] - 2s 64us/step - loss: 1.6998 - acc: 0.4186 - val_loss: 1.7191 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.72027 to 1.71908, saving model to ./model.h5\n",
      "Epoch 28/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.6976 - acc: 0.4227 - val_loss: 1.7191 - val_acc: 0.4162\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.71908 to 1.71907, saving model to ./model.h5\n",
      "Epoch 29/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6960 - acc: 0.4226 - val_loss: 1.7205 - val_acc: 0.4124\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.6939 - acc: 0.4219 - val_loss: 1.7186 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.71907 to 1.71858, saving model to ./model.h5\n",
      "Epoch 31/1000\n",
      "24129/24129 [==============================] - 2s 64us/step - loss: 1.6951 - acc: 0.4215 - val_loss: 1.7176 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.71858 to 1.71763, saving model to ./model.h5\n",
      "Epoch 32/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.6939 - acc: 0.4218 - val_loss: 1.7128 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.71763 to 1.71278, saving model to ./model.h5\n",
      "Epoch 33/1000\n",
      "24129/24129 [==============================] - 2s 63us/step - loss: 1.6912 - acc: 0.4228 - val_loss: 1.7099 - val_acc: 0.4185\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.71278 to 1.70995, saving model to ./model.h5\n",
      "Epoch 34/1000\n",
      "24129/24129 [==============================] - 2s 63us/step - loss: 1.6913 - acc: 0.4224 - val_loss: 1.7098 - val_acc: 0.4167\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.70995 to 1.70983, saving model to ./model.h5\n",
      "Epoch 35/1000\n",
      "24129/24129 [==============================] - 1s 60us/step - loss: 1.6901 - acc: 0.4224 - val_loss: 1.7111 - val_acc: 0.4149\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.6904 - acc: 0.4233 - val_loss: 1.7093 - val_acc: 0.4149\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.70983 to 1.70932, saving model to ./model.h5\n",
      "Epoch 37/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 1.6875 - acc: 0.4226 - val_loss: 1.7102 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.6871 - acc: 0.4241 - val_loss: 1.7073 - val_acc: 0.4209\n",
      "\n",
      "Epoch 00038: val_loss improved from 1.70932 to 1.70727, saving model to ./model.h5\n",
      "Epoch 39/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6847 - acc: 0.4233 - val_loss: 1.7112 - val_acc: 0.4202\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6860 - acc: 0.4243 - val_loss: 1.7116 - val_acc: 0.4194\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6860 - acc: 0.4248 - val_loss: 1.7058 - val_acc: 0.4194\n",
      "\n",
      "Epoch 00041: val_loss improved from 1.70727 to 1.70577, saving model to ./model.h5\n",
      "Epoch 42/1000\n",
      "24129/24129 [==============================] - 2s 66us/step - loss: 1.6829 - acc: 0.4240 - val_loss: 1.7037 - val_acc: 0.4194\n",
      "\n",
      "Epoch 00042: val_loss improved from 1.70577 to 1.70368, saving model to ./model.h5\n",
      "Epoch 43/1000\n",
      "24129/24129 [==============================] - 2s 66us/step - loss: 1.6827 - acc: 0.4253 - val_loss: 1.7039 - val_acc: 0.4210\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.6809 - acc: 0.4263 - val_loss: 1.7047 - val_acc: 0.4194\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6816 - acc: 0.4251 - val_loss: 1.7014 - val_acc: 0.4230\n",
      "\n",
      "Epoch 00045: val_loss improved from 1.70368 to 1.70141, saving model to ./model.h5\n",
      "Epoch 46/1000\n",
      "24129/24129 [==============================] - 1s 62us/step - loss: 1.6815 - acc: 0.4267 - val_loss: 1.7021 - val_acc: 0.4205\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.6793 - acc: 0.4246 - val_loss: 1.7030 - val_acc: 0.4175\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6774 - acc: 0.4243 - val_loss: 1.7042 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6757 - acc: 0.4266 - val_loss: 1.7007 - val_acc: 0.4205\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.70141 to 1.70065, saving model to ./model.h5\n",
      "Epoch 50/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6775 - acc: 0.4266 - val_loss: 1.7004 - val_acc: 0.4207\n",
      "\n",
      "Epoch 00050: val_loss improved from 1.70065 to 1.70037, saving model to ./model.h5\n",
      "Epoch 51/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.6761 - acc: 0.4267 - val_loss: 1.6998 - val_acc: 0.4151\n",
      "\n",
      "Epoch 00051: val_loss improved from 1.70037 to 1.69979, saving model to ./model.h5\n",
      "Epoch 52/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 1.6752 - acc: 0.4268 - val_loss: 1.7007 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 53/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6746 - acc: 0.4251 - val_loss: 1.6994 - val_acc: 0.4217\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.69979 to 1.69939, saving model to ./model.h5\n",
      "Epoch 54/1000\n",
      "24129/24129 [==============================] - 2s 62us/step - loss: 1.6750 - acc: 0.4254 - val_loss: 1.7042 - val_acc: 0.4137\n",
      "\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 55/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6734 - acc: 0.4267 - val_loss: 1.7029 - val_acc: 0.4210\n",
      "\n",
      "Epoch 00055: val_loss did not improve\n",
      "Epoch 56/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6742 - acc: 0.4246 - val_loss: 1.7011 - val_acc: 0.4154\n",
      "\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 57/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6711 - acc: 0.4271 - val_loss: 1.7139 - val_acc: 0.4107\n",
      "\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 58/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6707 - acc: 0.4271 - val_loss: 1.6960 - val_acc: 0.4207\n",
      "\n",
      "Epoch 00058: val_loss improved from 1.69939 to 1.69597, saving model to ./model.h5\n",
      "Epoch 59/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 1.6706 - acc: 0.4274 - val_loss: 1.6977 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 60/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6694 - acc: 0.4266 - val_loss: 1.7013 - val_acc: 0.4192\n",
      "\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 61/1000\n",
      "24129/24129 [==============================] - 1s 50us/step - loss: 1.6702 - acc: 0.4282 - val_loss: 1.6970 - val_acc: 0.4154\n",
      "\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 62/1000\n",
      "24129/24129 [==============================] - 1s 49us/step - loss: 1.6679 - acc: 0.4270 - val_loss: 1.6964 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 63/1000\n",
      "24129/24129 [==============================] - 1s 50us/step - loss: 1.6670 - acc: 0.4289 - val_loss: 1.6970 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 64/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6652 - acc: 0.4272 - val_loss: 1.6936 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00064: val_loss improved from 1.69597 to 1.69355, saving model to ./model.h5\n",
      "Epoch 65/1000\n",
      "24129/24129 [==============================] - 1s 62us/step - loss: 1.6680 - acc: 0.4288 - val_loss: 1.6937 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6645 - acc: 0.4266 - val_loss: 1.6946 - val_acc: 0.4189\n",
      "\n",
      "Epoch 00066: val_loss did not improve\n",
      "Epoch 67/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.6650 - acc: 0.4284 - val_loss: 1.6924 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00067: val_loss improved from 1.69355 to 1.69245, saving model to ./model.h5\n",
      "Epoch 68/1000\n",
      "24129/24129 [==============================] - 2s 64us/step - loss: 1.6639 - acc: 0.4280 - val_loss: 1.6900 - val_acc: 0.4237\n",
      "\n",
      "Epoch 00068: val_loss improved from 1.69245 to 1.68995, saving model to ./model.h5\n",
      "Epoch 69/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.6625 - acc: 0.4272 - val_loss: 1.6913 - val_acc: 0.4247\n",
      "\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 70/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6615 - acc: 0.4285 - val_loss: 1.7003 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00070: val_loss did not improve\n",
      "Epoch 71/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6635 - acc: 0.4283 - val_loss: 1.6946 - val_acc: 0.4169\n",
      "\n",
      "Epoch 00071: val_loss did not improve\n",
      "Epoch 72/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6601 - acc: 0.4277 - val_loss: 1.6981 - val_acc: 0.4175\n",
      "\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 73/1000\n",
      "24129/24129 [==============================] - 1s 49us/step - loss: 1.6617 - acc: 0.4251 - val_loss: 1.6928 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 74/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6617 - acc: 0.4289 - val_loss: 1.6915 - val_acc: 0.4159\n",
      "\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 75/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6609 - acc: 0.4287 - val_loss: 1.6897 - val_acc: 0.4235\n",
      "\n",
      "Epoch 00075: val_loss improved from 1.68995 to 1.68966, saving model to ./model.h5\n",
      "Epoch 76/1000\n",
      "24129/24129 [==============================] - 2s 71us/step - loss: 1.6580 - acc: 0.4296 - val_loss: 1.6935 - val_acc: 0.4205\n",
      "\n",
      "Epoch 00076: val_loss did not improve\n",
      "Epoch 77/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6613 - acc: 0.4263 - val_loss: 1.6932 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 78/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6577 - acc: 0.4294 - val_loss: 1.6934 - val_acc: 0.4235\n",
      "\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 79/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6556 - acc: 0.4321 - val_loss: 1.6905 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 80/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6552 - acc: 0.4304 - val_loss: 1.6916 - val_acc: 0.4209\n",
      "\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 81/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6556 - acc: 0.4298 - val_loss: 1.6885 - val_acc: 0.4210\n",
      "\n",
      "Epoch 00081: val_loss improved from 1.68966 to 1.68851, saving model to ./model.h5\n",
      "Epoch 82/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 1.6554 - acc: 0.4297 - val_loss: 1.6887 - val_acc: 0.4230\n",
      "\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 83/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 1.6560 - acc: 0.4275 - val_loss: 1.7003 - val_acc: 0.4185\n",
      "\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 84/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6548 - acc: 0.4306 - val_loss: 1.6913 - val_acc: 0.4190\n",
      "\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 85/1000\n",
      "24129/24129 [==============================] - 1s 49us/step - loss: 1.6558 - acc: 0.4296 - val_loss: 1.6884 - val_acc: 0.4252\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.68851 to 1.68840, saving model to ./model.h5\n",
      "Epoch 86/1000\n",
      "24129/24129 [==============================] - 1s 62us/step - loss: 1.6530 - acc: 0.4284 - val_loss: 1.6867 - val_acc: 0.4232\n",
      "\n",
      "Epoch 00086: val_loss improved from 1.68840 to 1.68669, saving model to ./model.h5\n",
      "Epoch 87/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.6550 - acc: 0.4278 - val_loss: 1.6910 - val_acc: 0.4258\n",
      "\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 88/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6496 - acc: 0.4305 - val_loss: 1.6866 - val_acc: 0.4243\n",
      "\n",
      "Epoch 00088: val_loss improved from 1.68669 to 1.68664, saving model to ./model.h5\n",
      "Epoch 89/1000\n",
      "24129/24129 [==============================] - 2s 63us/step - loss: 1.6510 - acc: 0.4305 - val_loss: 1.6904 - val_acc: 0.4215\n",
      "\n",
      "Epoch 00089: val_loss did not improve\n",
      "Epoch 90/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.6507 - acc: 0.4306 - val_loss: 1.6911 - val_acc: 0.4209\n",
      "\n",
      "Epoch 00090: val_loss did not improve\n",
      "Epoch 91/1000\n",
      "24129/24129 [==============================] - 1s 57us/step - loss: 1.6513 - acc: 0.4322 - val_loss: 1.6890 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00091: val_loss did not improve\n",
      "Epoch 92/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6512 - acc: 0.4309 - val_loss: 1.6852 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00092: val_loss improved from 1.68664 to 1.68521, saving model to ./model.h5\n",
      "Epoch 93/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6509 - acc: 0.4312 - val_loss: 1.6897 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00093: val_loss did not improve\n",
      "Epoch 94/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6502 - acc: 0.4311 - val_loss: 1.6860 - val_acc: 0.4222\n",
      "\n",
      "Epoch 00094: val_loss did not improve\n",
      "Epoch 95/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6495 - acc: 0.4285 - val_loss: 1.6886 - val_acc: 0.4243\n",
      "\n",
      "Epoch 00095: val_loss did not improve\n",
      "Epoch 96/1000\n",
      "24129/24129 [==============================] - 1s 50us/step - loss: 1.6488 - acc: 0.4327 - val_loss: 1.6868 - val_acc: 0.4223\n",
      "\n",
      "Epoch 00096: val_loss did not improve\n",
      "Epoch 97/1000\n",
      "24129/24129 [==============================] - 1s 50us/step - loss: 1.6490 - acc: 0.4326 - val_loss: 1.6861 - val_acc: 0.4237\n",
      "\n",
      "Epoch 00097: val_loss did not improve\n",
      "Epoch 98/1000\n",
      "24129/24129 [==============================] - 1s 48us/step - loss: 1.6482 - acc: 0.4315 - val_loss: 1.6843 - val_acc: 0.4257\n",
      "\n",
      "Epoch 00098: val_loss improved from 1.68521 to 1.68426, saving model to ./model.h5\n",
      "Epoch 99/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.6478 - acc: 0.4314 - val_loss: 1.6836 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.68426 to 1.68357, saving model to ./model.h5\n",
      "Epoch 100/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6463 - acc: 0.4315 - val_loss: 1.6878 - val_acc: 0.4263\n",
      "\n",
      "Epoch 00100: val_loss did not improve\n",
      "Epoch 101/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6463 - acc: 0.4339 - val_loss: 1.6944 - val_acc: 0.4194\n",
      "\n",
      "Epoch 00101: val_loss did not improve\n",
      "Epoch 102/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6466 - acc: 0.4314 - val_loss: 1.6836 - val_acc: 0.4273\n",
      "\n",
      "Epoch 00102: val_loss did not improve\n",
      "Epoch 103/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6427 - acc: 0.4362 - val_loss: 1.6908 - val_acc: 0.4240\n",
      "\n",
      "Epoch 00103: val_loss did not improve\n",
      "Epoch 104/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6432 - acc: 0.4340 - val_loss: 1.6880 - val_acc: 0.4200\n",
      "\n",
      "Epoch 00104: val_loss did not improve\n",
      "Epoch 105/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6446 - acc: 0.4335 - val_loss: 1.6835 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00105: val_loss improved from 1.68357 to 1.68350, saving model to ./model.h5\n",
      "Epoch 106/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6430 - acc: 0.4366 - val_loss: 1.6833 - val_acc: 0.4272\n",
      "\n",
      "Epoch 00106: val_loss improved from 1.68350 to 1.68328, saving model to ./model.h5\n",
      "Epoch 107/1000\n",
      "24129/24129 [==============================] - 1s 62us/step - loss: 1.6423 - acc: 0.4357 - val_loss: 1.6873 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00107: val_loss did not improve\n",
      "Epoch 108/1000\n",
      "24129/24129 [==============================] - 1s 48us/step - loss: 1.6417 - acc: 0.4349 - val_loss: 1.6833 - val_acc: 0.4270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00108: val_loss did not improve\n",
      "Epoch 109/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6418 - acc: 0.4331 - val_loss: 1.6843 - val_acc: 0.4276\n",
      "\n",
      "Epoch 00109: val_loss did not improve\n",
      "Epoch 110/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6437 - acc: 0.4352 - val_loss: 1.6860 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00110: val_loss did not improve\n",
      "Epoch 111/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 1.6429 - acc: 0.4331 - val_loss: 1.6836 - val_acc: 0.4228\n",
      "\n",
      "Epoch 00111: val_loss did not improve\n",
      "Epoch 112/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.6401 - acc: 0.4336 - val_loss: 1.6952 - val_acc: 0.4232\n",
      "\n",
      "Epoch 00112: val_loss did not improve\n",
      "Epoch 113/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6408 - acc: 0.4336 - val_loss: 1.6827 - val_acc: 0.4257\n",
      "\n",
      "Epoch 00113: val_loss improved from 1.68328 to 1.68275, saving model to ./model.h5\n",
      "Epoch 114/1000\n",
      "24129/24129 [==============================] - 2s 66us/step - loss: 1.6405 - acc: 0.4332 - val_loss: 1.6838 - val_acc: 0.4262\n",
      "\n",
      "Epoch 00114: val_loss did not improve\n",
      "Epoch 115/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6383 - acc: 0.4364 - val_loss: 1.6864 - val_acc: 0.4258\n",
      "\n",
      "Epoch 00115: val_loss did not improve\n",
      "Epoch 116/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6408 - acc: 0.4341 - val_loss: 1.6971 - val_acc: 0.4243\n",
      "\n",
      "Epoch 00116: val_loss did not improve\n",
      "Epoch 117/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6368 - acc: 0.4359 - val_loss: 1.6827 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00117: val_loss improved from 1.68275 to 1.68272, saving model to ./model.h5\n",
      "Epoch 118/1000\n",
      "24129/24129 [==============================] - 1s 61us/step - loss: 1.6387 - acc: 0.4340 - val_loss: 1.6835 - val_acc: 0.4268\n",
      "\n",
      "Epoch 00118: val_loss did not improve\n",
      "Epoch 119/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6378 - acc: 0.4367 - val_loss: 1.6890 - val_acc: 0.4220\n",
      "\n",
      "Epoch 00119: val_loss did not improve\n",
      "Epoch 120/1000\n",
      "24129/24129 [==============================] - 1s 50us/step - loss: 1.6407 - acc: 0.4344 - val_loss: 1.6844 - val_acc: 0.4258\n",
      "\n",
      "Epoch 00120: val_loss did not improve\n",
      "Epoch 121/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6370 - acc: 0.4361 - val_loss: 1.6815 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00121: val_loss improved from 1.68272 to 1.68149, saving model to ./model.h5\n",
      "Epoch 122/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.6371 - acc: 0.4365 - val_loss: 1.6824 - val_acc: 0.4272\n",
      "\n",
      "Epoch 00122: val_loss did not improve\n",
      "Epoch 123/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6365 - acc: 0.4353 - val_loss: 1.6936 - val_acc: 0.4213\n",
      "\n",
      "Epoch 00123: val_loss did not improve\n",
      "Epoch 124/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6368 - acc: 0.4366 - val_loss: 1.6865 - val_acc: 0.4275\n",
      "\n",
      "Epoch 00124: val_loss did not improve\n",
      "Epoch 125/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 1.6370 - acc: 0.4370 - val_loss: 1.6803 - val_acc: 0.4278\n",
      "\n",
      "Epoch 00125: val_loss improved from 1.68149 to 1.68032, saving model to ./model.h5\n",
      "Epoch 126/1000\n",
      "24129/24129 [==============================] - 1s 59us/step - loss: 1.6352 - acc: 0.4362 - val_loss: 1.6864 - val_acc: 0.4245\n",
      "\n",
      "Epoch 00126: val_loss did not improve\n",
      "Epoch 127/1000\n",
      "24129/24129 [==============================] - 1s 53us/step - loss: 1.6352 - acc: 0.4362 - val_loss: 1.6805 - val_acc: 0.4243\n",
      "\n",
      "Epoch 00127: val_loss did not improve\n",
      "Epoch 128/1000\n",
      "24129/24129 [==============================] - 1s 51us/step - loss: 1.6345 - acc: 0.4358 - val_loss: 1.6793 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00128: val_loss improved from 1.68032 to 1.67932, saving model to ./model.h5\n",
      "Epoch 129/1000\n",
      "24129/24129 [==============================] - 2s 63us/step - loss: 1.6345 - acc: 0.4359 - val_loss: 1.6806 - val_acc: 0.4265\n",
      "\n",
      "Epoch 00129: val_loss did not improve\n",
      "Epoch 130/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.6330 - acc: 0.4381 - val_loss: 1.6850 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00130: val_loss did not improve\n",
      "Epoch 131/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6323 - acc: 0.4386 - val_loss: 1.6802 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00131: val_loss did not improve\n",
      "Epoch 132/1000\n",
      "24129/24129 [==============================] - 1s 54us/step - loss: 1.6337 - acc: 0.4339 - val_loss: 1.6804 - val_acc: 0.4260\n",
      "\n",
      "Epoch 00132: val_loss did not improve\n",
      "Epoch 133/1000\n",
      "24129/24129 [==============================] - 1s 52us/step - loss: 1.6329 - acc: 0.4366 - val_loss: 1.6869 - val_acc: 0.4281\n",
      "\n",
      "Epoch 00133: val_loss did not improve\n",
      "Epoch 134/1000\n",
      "24129/24129 [==============================] - 1s 56us/step - loss: 1.6342 - acc: 0.4370 - val_loss: 1.6820 - val_acc: 0.4270\n",
      "\n",
      "Epoch 00134: val_loss did not improve\n",
      "Epoch 135/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6332 - acc: 0.4368 - val_loss: 1.6875 - val_acc: 0.4265\n",
      "\n",
      "Epoch 00135: val_loss did not improve\n",
      "Epoch 136/1000\n",
      "24129/24129 [==============================] - 1s 58us/step - loss: 1.6315 - acc: 0.4374 - val_loss: 1.6870 - val_acc: 0.4242\n",
      "\n",
      "Epoch 00136: val_loss did not improve\n",
      "Epoch 137/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6324 - acc: 0.4374 - val_loss: 1.6841 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00137: val_loss did not improve\n",
      "Epoch 138/1000\n",
      "24129/24129 [==============================] - 1s 55us/step - loss: 1.6295 - acc: 0.4392 - val_loss: 1.6830 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00138: val_loss did not improve\n",
      "Epoch 00138: early stopping\n",
      "[INFO] Best loss: 1.6295330189923423\n",
      "[INFO] Best acc: 0.4392225124061397\n",
      "[INFO] Best val_loss: 1.6793195418649183\n",
      "[INFO] Best val_acc: 0.4281452014046918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 建構 model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, input_shape=(X_train.shape[1],), activation=\"sigmoid\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dense(32, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.05))\n",
    "model.add(layers.Dense(16, activation=\"relu\"))\n",
    "model.add(layers.Dense(16, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 顯示模型摘要與結構\n",
    "model.summary()\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=10, mode='auto', verbose=1)\n",
    "checkpointer = ModelCheckpoint('./model.h5',verbose=1, save_best_only=True)\n",
    "\n",
    "# 開始訓練 model\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=1000, batch_size=128, callbacks=[es,checkpointer])\n",
    "\n",
    "print(\"[INFO] Best loss: {}\".format(np.min(history.history['loss'])))\n",
    "print(\"[INFO] Best acc: {}\".format(np.max(history.history['acc'])))\n",
    "print(\"[INFO] Best val_loss: {}\".format(np.min(history.history['val_loss'])))\n",
    "print(\"[INFO] Best val_acc: {}\".format(np.max(history.history['val_acc'])))\n",
    "\n",
    "plt.plot(history.history['acc'], label='acc')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Model Performance')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15060/15060 [==============================] - 1s 58us/step\n",
      "Test Acc : 0.43120849930432686\n",
      "Test Loss : 1.6822514841122773\n"
     ]
    }
   ],
   "source": [
    "# 評估指標\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Acc : \" + str(accuracy))\n",
    "print(\"Test Loss : \" + str(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "        max_value=max(y_pred[i])\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if max_value==y_pred[i][j]:\n",
    "                y_pred[i][j]=1\n",
    "            else:\n",
    "                y_pred[i][j]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.3638863947756511\n",
      "Recall : 0.43120849933598937\n",
      "F1 : 0.3615557206830723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\CV2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Precision : ' + str(precision_score(y_true, y_pred, average='weighted')))\n",
    "print('Recall : ' + str(recall_score(y_true, y_pred, average='weighted')))\n",
    "print('F1 : ' + str(f1_score(y_true,  y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
